{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtLuKRl8mIgkIczN9Fr8Y2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CardosoJr/bootcamp/blob/main/Labs/Applications/Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Segmentation\n"
      ],
      "metadata": {
        "id": "beFx8H-gVPWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste notebook, vamos gerar algumas formas de segmentação.\n",
        "\n",
        "O método tradicional é o chamado RFM, onde criamos features:\n",
        "- Recência (R): o quão recente foi a última compra do cliente\n",
        "- Frequência (F): a frequência de compras do cliente\n",
        "- Valor Monetário (M): o total gasto pelo cliente no histórico\n",
        "\n",
        "Inicialmente, vamos apresentar algumas abordagens sem feature engineering."
      ],
      "metadata": {
        "id": "z33QhXuLVTe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap -q\n",
        "!pip install pyod -q\n",
        "!pip install yellowbrick -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D-eXNVCVqyD",
        "outputId": "ede81bb8-fd5a-4490-aab7-9f98f6ff3cd6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/533.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/533.5 kB\u001b[0m \u001b[31m945.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/533.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m460.8/533.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfaPsrFAIrL3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # dataframe manipulation\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "# data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "# sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, classification_report\n",
        "\n",
        "from pyod.models.ecod import ECOD\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "import lightgbm as lgb\n",
        "import prince"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções Auxiliares"
      ],
      "metadata": {
        "id": "21zlqzOyjaKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pca_2d(df, predict):\n",
        "\n",
        "    pca_2d_object = prince.PCA(\n",
        "    n_components=2,\n",
        "    n_iter=3,\n",
        "    rescale_with_mean=True,\n",
        "    rescale_with_std=True,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='sklearn',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "    pca_2d_object.fit(df)\n",
        "\n",
        "    df_pca_2d = pca_2d_object.transform(df)\n",
        "    df_pca_2d.columns = [\"comp1\", \"comp2\"]\n",
        "    df_pca_2d[\"cluster\"] = predict\n",
        "\n",
        "    return pca_2d_object, df_pca_2d\n",
        "\n",
        "\n",
        "\n",
        "def get_pca_3d(df, predict):\n",
        "\n",
        "    pca_3d_object = prince.PCA(\n",
        "    n_components=3,\n",
        "    n_iter=3,\n",
        "    rescale_with_mean=True,\n",
        "    rescale_with_std=True,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='sklearn',\n",
        "    random_state=42\n",
        "    )\n",
        "\n",
        "    pca_3d_object.fit(df)\n",
        "\n",
        "    df_pca_3d = pca_3d_object.transform(df)\n",
        "    df_pca_3d.columns = [\"comp1\", \"comp2\", \"comp3\"]\n",
        "    df_pca_3d[\"cluster\"] = predict\n",
        "\n",
        "    return pca_3d_object, df_pca_3d\n",
        "\n",
        "\n",
        "\n",
        "def plot_pca_3d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
        "\n",
        "    df = df.astype({\"cluster\": \"object\"})\n",
        "    df = df.sort_values(\"cluster\")\n",
        "\n",
        "    fig = px.scatter_3d(df,\n",
        "                        x='comp1',\n",
        "                        y='comp2',\n",
        "                        z='comp3',\n",
        "                        color='cluster',\n",
        "                        template=\"plotly\",\n",
        "\n",
        "                        # symbol = \"cluster\",\n",
        "\n",
        "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
        "                        title=title).update_traces(\n",
        "                            # mode = 'markers',\n",
        "                            marker={\n",
        "                                \"size\": 4,\n",
        "                                \"opacity\": opacity,\n",
        "                                # \"symbol\" : \"diamond\",\n",
        "                                \"line\": {\n",
        "                                    \"width\": width_line,\n",
        "                                    \"color\": \"black\",\n",
        "                                }\n",
        "                            }\n",
        "                        ).update_layout(\n",
        "                                width = 1000,\n",
        "                                height = 800,\n",
        "                                autosize = False,\n",
        "                                showlegend = True,\n",
        "                                legend=dict(title_font_family=\"Times New Roman\",\n",
        "                                            font=dict(size= 20)),\n",
        "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
        "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
        "                                            zaxis=dict(title = 'comp3', titlefont_color = 'black')),\n",
        "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
        "\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def plot_pca_2d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
        "\n",
        "    df = df.astype({\"cluster\": \"object\"})\n",
        "    df = df.sort_values(\"cluster\")\n",
        "\n",
        "    fig = px.scatter(df,\n",
        "                        x='comp1',\n",
        "                        y='comp2',\n",
        "                        color='cluster',\n",
        "                        template=\"plotly\",\n",
        "                        # symbol = \"cluster\",\n",
        "\n",
        "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
        "                        title=title).update_traces(\n",
        "                            # mode = 'markers',\n",
        "                            marker={\n",
        "                                \"size\": 8,\n",
        "                                \"opacity\": opacity,\n",
        "                                # \"symbol\" : \"diamond\",\n",
        "                                \"line\": {\n",
        "                                    \"width\": width_line,\n",
        "                                    \"color\": \"black\",\n",
        "                                }\n",
        "                            }\n",
        "                        ).update_layout(\n",
        "                                width = 800,\n",
        "                                height = 700,\n",
        "                                autosize = False,\n",
        "                                showlegend = True,\n",
        "                                legend=dict(title_font_family=\"Times New Roman\",\n",
        "                                            font=dict(size= 20)),\n",
        "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
        "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
        "                                            ),\n",
        "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
        "\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "vCfDa1FmjbqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding usando LLMs"
      ],
      "metadata": {
        "id": "9xY9BLYkjTQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # dataframe manipulation\n",
        "import numpy as np # linear algebra\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "df = pd.read_csv(\"data/train.csv\", sep = \";\")\n",
        "\n",
        "def compile_text(x):\n",
        "\n",
        "\n",
        "    text =  f\"\"\"Age: {x['age']},\n",
        "                housing load: {x['housing']},\n",
        "                Job: {x['job']},\n",
        "                Marital: {x['marital']},\n",
        "                Education: {x['education']},\n",
        "                Default: {x['default']},\n",
        "                Balance: {x['balance']},\n",
        "                Personal loan: {x['loan']}\n",
        "            \"\"\"\n",
        "\n",
        "    return text\n",
        "\n",
        "sentences = df.apply(lambda x: compile_text(x), axis=1).tolist()\n",
        "\n",
        "\n",
        "\n",
        "model = SentenceTransformer(r\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
        "\n",
        "output = model.encode(sentences=sentences, show_progress_bar= True, normalize_embeddings  = True)\n",
        "\n",
        "df_embedding = pd.DataFrame(output)\n",
        "df_embedding\n",
        "\n",
        "\n",
        "df_embedding.to_csv(\"embedding_train.csv\",index = False)"
      ],
      "metadata": {
        "id": "2vQjhC-cjOKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisando Clusters"
      ],
      "metadata": {
        "id": "XmeaLMA7jnnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/train.csv\", sep = \";\")\n",
        "df = df.iloc[:, 0:8]"
      ],
      "metadata": {
        "id": "7UHQbm1SjiN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.ecod import ECOD\n",
        "# https://github.com/yzhao062/pyod\n",
        "\n",
        "clf = ECOD()\n",
        "clf.fit(df_embedding)\n",
        "\n",
        "\n",
        "out = clf.predict(df_embedding)\n",
        "df_embedding[\"outliers\"] = out\n",
        "df[\"outliers\"] = out\n",
        "\n",
        "df_embedding_no_out = df_embedding[df_embedding[\"outliers\"] == 0]\n",
        "df_embedding_no_out = df_embedding_no_out.drop([\"outliers\"], axis = 1)\n",
        "\n",
        "\n",
        "df_embedding_with_out = df_embedding.copy()\n",
        "df_embedding_with_out = df_embedding_with_out.drop([\"outliers\"], axis = 1)"
      ],
      "metadata": {
        "id": "blFcROrFjP_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the clustering model and visualizer\n",
        "km = KMeans(init=\"k-means++\", random_state=0, n_init=\"auto\")\n",
        "visualizer = KElbowVisualizer(km, k=(2,10), locate_elbow=False)\n",
        "\n",
        "visualizer.fit(df_embedding_with_out)        # Fit the data to the visualizer\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "--MJipDgjrhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 5\n"
      ],
      "metadata": {
        "id": "dWlrwxkkjtpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = KMeans(n_clusters=n_clusters, init = \"k-means++\").fit(df_embedding_no_out)\n",
        "print(clusters.inertia_)\n",
        "clusters_predict = clusters.predict(df_embedding_no_out)"
      ],
      "metadata": {
        "id": "NlmlDLiNjvQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "\"\"\"\n",
        "The Davies Bouldin index is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances.\n",
        "The minimum value of the DB Index is 0, whereas a smaller value (closer to 0) represents a better model that produces better clusters.\n",
        "\"\"\"\n",
        "print(f\"Davies bouldin score: {davies_bouldin_score(df_embedding_no_out,clusters_predict)}\")\n",
        "\n",
        "\"\"\"\n",
        "Calinski Harabaz Index -> Variance Ratio Criterion.\n",
        "Calinski Harabaz Index is defined as the ratio of the sum of between-cluster dispersion and of within-cluster dispersion.\n",
        "The higher the index the more separable the clusters.\n",
        "\"\"\"\n",
        "print(f\"Calinski Score: {calinski_harabasz_score(df_embedding_no_out,clusters_predict)}\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "The silhouette score is a metric used to calculate the goodness of fit of a clustering algorithm, but can also be used as a method for determining an optimal value of k (see here for more).\n",
        "Its value ranges from -1 to 1.\n",
        "A value of 0 indicates clusters are overlapping and either the data or the value of k is incorrect.\n",
        "1 is the ideal value and indicates that clusters are very dense and nicely separated.\n",
        "\"\"\"\n",
        "print(f\"Silhouette Score: {silhouette_score(df_embedding_no_out,clusters_predict)}\")"
      ],
      "metadata": {
        "id": "9QnSwjNajxoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Projeções para Visualização"
      ],
      "metadata": {
        "id": "KNjp3nCLj2lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_3d_object, df_pca_3d = get_pca_3d(df_embedding_no_out, clusters_predict)\n",
        "plot_pca_3d(df_pca_3d, title = \"PCA Space\", opacity=1, width_line = 0.1)\n",
        "print(\"The variability is :\", pca_3d_object.eigenvalues_summary)"
      ],
      "metadata": {
        "id": "8Cnd0eQNjx8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_2d_object, df_pca_2d = get_pca_2d(df_embedding_no_out, clusters_predict)\n",
        "plot_pca_2d(df_pca_2d, title = \"PCA Space\", opacity=1, width_line = 0.2)"
      ],
      "metadata": {
        "id": "5rz9_0Qnj079"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_data = df_embedding_no_out.sample(frac=0.5, replace=True, random_state=1)\n",
        "sampling_clusters = pd.DataFrame(clusters_predict).sample(frac=0.5, replace=True, random_state=1)[0].values\n",
        "\n",
        "df_tsne_3d = TSNE(\n",
        "                  n_components=3,\n",
        "                  learning_rate=500,\n",
        "                  init='random',\n",
        "                  perplexity=200,\n",
        "                  n_iter = 5000).fit_transform(sampling_data)\n",
        "\n",
        "df_tsne_3d = pd.DataFrame(df_tsne_3d, columns=[\"comp1\", \"comp2\",'comp3'])\n",
        "df_tsne_3d[\"cluster\"] = sampling_clusters\n",
        "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=1, width_line = 0.1)"
      ],
      "metadata": {
        "id": "c_zQC-7Oj1Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_3d(df_tsne_3d, title = \"T-SNE Space\", opacity=0.1, width_line = 0.1)\n"
      ],
      "metadata": {
        "id": "q2wQjuDaj54-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tsne_2d = TSNE(\n",
        "                  n_components=2,\n",
        "                  learning_rate=500,\n",
        "                  init='random',\n",
        "                  perplexity=200,\n",
        "                  n_iter = 5000).fit_transform(sampling_data)\n",
        "\n",
        "df_tsne_2d = pd.DataFrame(df_tsne_2d, columns=[\"comp1\", \"comp2\"])\n",
        "df_tsne_2d[\"cluster\"] = sampling_clusters\n",
        "\n",
        "plot_pca_2d(df_tsne_2d, title = \"PCA Space\", opacity=0.5, width_line = 0.5)"
      ],
      "metadata": {
        "id": "z3BR1SNej6BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pca_2d(df_tsne_2d, title = \"PCA Space\", opacity=1, width_line = 0.5)\n"
      ],
      "metadata": {
        "id": "XdX7aJnoj75D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explicabilidade dos Clusters"
      ],
      "metadata": {
        "id": "ZkdNYf6Zj9eJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers = df[df[\"outliers\"] == 0]\n",
        "df_no_outliers = df_no_outliers.drop(\"outliers\", axis = 1)"
      ],
      "metadata": {
        "id": "wZmsDxMfj_tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_km = lgb.LGBMClassifier(colsample_by_tree=0.8)\n",
        "\n",
        "for col in [\"job\", \"marital\", \"education\", \"housing\", \"loan\", \"default\"]:\n",
        "    df_no_outliers[col] = df_no_outliers[col].astype('category')\n",
        "\n",
        "clf_km.fit(X = df_no_outliers , y = clusters_predict)\n",
        "\n",
        "#SHAP values\n",
        "explainer_km = shap.TreeExplainer(clf_km)\n",
        "shap_values_km = explainer_km.shap_values(df_no_outliers)\n",
        "shap.summary_plot(shap_values_km, df_no_outliers, plot_type=\"bar\", plot_size=(15, 10))"
      ],
      "metadata": {
        "id": "osTq11rqkBHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf_km.predict(df_no_outliers)\n",
        "accuracy=accuracy_score(y_pred, clusters_predict)\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy))\n",
        "print(classification_report(clusters_predict, y_pred))"
      ],
      "metadata": {
        "id": "LuTfVKU7kD5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers[\"cluster\"] = clusters_predict\n",
        "\n",
        "df_group = df_no_outliers.groupby('cluster').agg(\n",
        "    {\n",
        "        'job': lambda x: x.value_counts().index[0],\n",
        "        'marital': lambda x: x.value_counts().index[0],\n",
        "        'education': lambda x: x.value_counts().index[0],\n",
        "        'housing': lambda x: x.value_counts().index[0],\n",
        "        'loan': lambda x: x.value_counts().index[0],\n",
        "        'age':'mean',\n",
        "        'balance': 'mean',\n",
        "        'default': lambda x: x.value_counts().index[0],\n",
        "\n",
        "    }\n",
        ").sort_values(\"job\").reset_index()\n",
        "df_group"
      ],
      "metadata": {
        "id": "ab4QqJcVkG2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}